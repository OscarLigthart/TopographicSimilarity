{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINE THE PATHS\n",
    "path_related = '../runs/lstm_max_len_5_vocab_5_same_data_attr_4_related_split_2/'\n",
    "path = '../runs/lstm_max_len_5_vocab_5_same_data_attr_4_split_2/'\n",
    "\n",
    "# set save path to \"\" if we use old data\n",
    "#save_path = 'Experiments/'\n",
    "save_path = \"\"\n",
    "\n",
    "# DETERMINE THE SEED\n",
    "seed = '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract model state dict\n",
    "\n",
    "# import pickle\n",
    "model_path = path + seed + '/model.p'\n",
    "state = torch.load(model_path)\n",
    "receiver_state = state['receiver']\n",
    "\n",
    "# import related pickle\n",
    "model_path = path_related + seed + '/model.p'\n",
    "state = torch.load(model_path)\n",
    "receiver_state_related = state['receiver']\n",
    "\n",
    "if not os.path.exists(save_path + seed):\n",
    "    os.makedirs(save_path + seed)\n",
    "\n",
    "# MAYBE JUST USE THE LSTM LAYER? --> skip the output module\n",
    "# save this there why not\n",
    "torch.save(receiver_state, save_path + seed + '/model.p')\n",
    "torch.save(receiver_state_related, save_path + seed+'/model_related.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust state dict\n",
    "We need to adjust the state dict such that the encoder and decoder keys have the right name. These should be: 'encoder.weight', 'decoder.weight' and 'decoder.bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# load the old state dict\n",
    "dicts = [];\n",
    "dicts.append(torch.load(save_path + seed + '/model.p'))\n",
    "dicts.append(torch.load(save_path + seed + '/model_related.p'))\n",
    " \n",
    "for j, state in enumerate(dicts):\n",
    "    \n",
    "    # create a new state dict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    # insert new keys and values into state dict\n",
    "    for i, (key,value) in enumerate(state.items()):\n",
    "\n",
    "        if i==0:\n",
    "            key = 'encoder.weight'\n",
    "        elif i == len(state.keys()) - 2:\n",
    "            key = 'decoder.weight'\n",
    "        elif i == len(state.keys()) - 1:\n",
    "            key = 'decoder.bias'\n",
    "\n",
    "        new_state_dict[key] = value\n",
    "\n",
    "    if j == 0:\n",
    "        torch.save(new_state_dict, save_path + seed + '/model.p')\n",
    "    else:\n",
    "        torch.save(new_state_dict, save_path + seed + '/model_related.p')\n",
    "        \n",
    "# for key,value in state.item():\n",
    "#     layer_name, weights = new[count]      \n",
    "# mymodel_kvpair[key]=weights\n",
    "# count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract vocabulary --> use integers\n",
    "\n",
    "vocab = pickle.load(open('../data/dict_5.pckl', 'rb'))\n",
    "\n",
    "# extract the values\n",
    "vocab_i = vocab['stoi'].values()\n",
    "\n",
    "# vocab should be an integer of 0 to 8\n",
    "f = open(\"vocab.txt\",\"w+\")\n",
    "\n",
    "for v in vocab_i:\n",
    "    f.write(\"%d\\n\" % (v))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vocab should be an integer of 0 to 8\n",
    "f = open(save_path+ seed+ \"/vocab20.txt\",\"w+\")\n",
    "\n",
    "for v in range(20):\n",
    "    f.write(\"%d\\n\" % (v))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Extract baseline corpus #\n",
    "###########################\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path + seed +'/metrics_at_10000.pkl', 'rb'))['messages']\n",
    "\n",
    "# create a new file\n",
    "f = open(save_path + seed + \"/corpus.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "# add the target?\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "##########################\n",
    "# Extract Related corpus #\n",
    "##########################\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path_related + seed +'/metrics_at_10000.pkl', 'rb'))['messages']\n",
    "\n",
    "# create a new file\n",
    "f = open(save_path + seed + \"/corpus_related.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "# add the target?\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "#print(messages.astype(int))\n",
    "\n",
    "#np.savetxt(\"data/corpus.txt\", messages.astype(int), delimiter=' ', fmt=\"%i\");\n",
    "\n",
    "# reload and add or customly make it by uncommenting the code above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get corpus of generalize set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract corpus\n",
    "\n",
    "# start with having the messages in one line\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path + seed + '/generalize_metrics.pkl', 'rb'))['messages']\n",
    "\n",
    "# create a new file\n",
    "f = open(save_path + seed + \"/corpus_generalize.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "# start with having the messages in one line\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path_related+ seed + '/generalize_metrics.pkl', 'rb'))['messages']\n",
    "\n",
    "# create a new file\n",
    "f = open(save_path + seed + \"/corpus_generalize_related.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path + seed +'/metrics_at_10000.pkl', 'rb'))['messages']\n",
    "\n",
    "# create a new file\n",
    "f = open(save_path+seed+\"/corpus_full.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path + seed + '/generalize_metrics.pkl', 'rb'))['messages']\n",
    "\n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "##########################\n",
    "# Extract Related corpus #\n",
    "##########################\n",
    "\n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path_related + seed +'/metrics_at_10000.pkl', 'rb'))['messages']\n",
    "\n",
    "# we take every 4th, since the targets are presented multiple times to the agents\n",
    "messages = messages[0::4]\n",
    "  \n",
    "# create a new file\n",
    "f = open(save_path+seed+\"/corpus_full_related.txt\",\"w+\")\n",
    "   \n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "# load the final messages from the training? or the gen? can easily alter this afterwards\n",
    "messages = pickle.load(open(path_related + seed + '/generalize_metrics.pkl', 'rb'))['messages']\n",
    "\n",
    "\n",
    "# write down the message\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        f.write(\"%i \" % (char))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# close the file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
