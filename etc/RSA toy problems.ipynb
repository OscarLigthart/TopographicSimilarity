{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file structre\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# import packages\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from itertools import combinations\n",
    "from scipy import spatial\n",
    "from metrics import rsa\n",
    "from data import one_hot, generate_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_distance_score(x, y):\n",
    "    \"\"\"\n",
    "    Jaccard Similarity J (A,B) = | Intersection (A,B) | /\n",
    "                                    | Union (A,B) |\n",
    "    \"\"\"\n",
    "    intersection_cardinality = len(set(x).intersection(set(y)))\n",
    "    union_cardinality = len(set(x).union(set(y)))\n",
    "\n",
    "    # 1 - result since we want the distance\n",
    "    return 1 - (intersection_cardinality / float(union_cardinality))\n",
    "\n",
    "def levenshtein_ratio_and_distance(s, t):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of s and the\n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    distance = np.zeros((rows, cols), dtype=int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # If we choose to calculate the ratio the cost of a substitution is 2.\n",
    "                cost = 2\n",
    "\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "\n",
    "    # Computation of the Levenshtein Distance Ratio\n",
    "    Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "    return (1-Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Compositional language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[['a', 'n'], ['a', 'o'], ['a', 'p'], ['a', 'q'], ['a', 'r'], ['a', 's'], ['a', 't'], ['a', 'u'], ['a', 'v'], ['a', 'w'], ['a', 'x'], ['a', 'y'], ['a', 'z'], ['b', 'n'], ['b', 'o'], ['b', 'p'], ['b', 'q'], ['b', 'r'], ['b', 's'], ['b', 't'], ['b', 'u'], ['b', 'v'], ['b', 'w'], ['b', 'x'], ['b', 'y'], ['b', 'z'], ['c', 'n'], ['c', 'o'], ['c', 'p'], ['c', 'q'], ['c', 'r'], ['c', 's'], ['c', 't'], ['c', 'u'], ['c', 'v'], ['c', 'w'], ['c', 'x'], ['c', 'y'], ['c', 'z'], ['d', 'n'], ['d', 'o'], ['d', 'p'], ['d', 'q'], ['d', 'r'], ['d', 's'], ['d', 't'], ['d', 'u'], ['d', 'v'], ['d', 'w'], ['d', 'x'], ['d', 'y'], ['d', 'z'], ['e', 'n'], ['e', 'o'], ['e', 'p'], ['e', 'q'], ['e', 'r'], ['e', 's'], ['e', 't'], ['e', 'u'], ['e', 'v'], ['e', 'w'], ['e', 'x'], ['e', 'y'], ['e', 'z'], ['f', 'n'], ['f', 'o'], ['f', 'p'], ['f', 'q'], ['f', 'r'], ['f', 's'], ['f', 't'], ['f', 'u'], ['f', 'v'], ['f', 'w'], ['f', 'x'], ['f', 'y'], ['f', 'z'], ['g', 'n'], ['g', 'o'], ['g', 'p'], ['g', 'q'], ['g', 'r'], ['g', 's'], ['g', 't'], ['g', 'u'], ['g', 'v'], ['g', 'w'], ['g', 'x'], ['g', 'y'], ['g', 'z'], ['h', 'n'], ['h', 'o'], ['h', 'p'], ['h', 'q'], ['h', 'r'], ['h', 's'], ['h', 't'], ['h', 'u'], ['h', 'v'], ['h', 'w'], ['h', 'x'], ['h', 'y'], ['h', 'z'], ['i', 'n'], ['i', 'o'], ['i', 'p'], ['i', 'q'], ['i', 'r'], ['i', 's'], ['i', 't'], ['i', 'u'], ['i', 'v'], ['i', 'w'], ['i', 'x'], ['i', 'y'], ['i', 'z'], ['j', 'n'], ['j', 'o'], ['j', 'p'], ['j', 'q'], ['j', 'r'], ['j', 's'], ['j', 't'], ['j', 'u'], ['j', 'v'], ['j', 'w'], ['j', 'x'], ['j', 'y'], ['j', 'z'], ['k', 'n'], ['k', 'o'], ['k', 'p'], ['k', 'q'], ['k', 'r'], ['k', 's'], ['k', 't'], ['k', 'u'], ['k', 'v'], ['k', 'w'], ['k', 'x'], ['k', 'y'], ['k', 'z'], ['l', 'n'], ['l', 'o'], ['l', 'p'], ['l', 'q'], ['l', 'r'], ['l', 's'], ['l', 't'], ['l', 'u'], ['l', 'v'], ['l', 'w'], ['l', 'x'], ['l', 'y'], ['l', 'z'], ['m', 'n'], ['m', 'o'], ['m', 'p'], ['m', 'q'], ['m', 'r'], ['m', 's'], ['m', 't'], ['m', 'u'], ['m', 'v'], ['m', 'w'], ['m', 'x'], ['m', 'y'], ['m', 'z']]\n"
     ]
    }
   ],
   "source": [
    "shapes = 13\n",
    "colors = 13\n",
    "\n",
    "# create vocabulary\n",
    "vocab = []\n",
    "alpha = 'a'\n",
    "for i in range(0, shapes+colors): \n",
    "    vocab.append(alpha) \n",
    "    alpha = chr(ord(alpha) + 1)  \n",
    "\n",
    "# create example datasetLanguage\n",
    "data = generate_dataset([shapes, colors])\n",
    "\n",
    "# create compositional messages\n",
    "messages = []\n",
    "for i in range(shapes):\n",
    "    for j in range(colors):\n",
    "        \n",
    "        # create message\n",
    "        message = [vocab[i], vocab[shapes + j]]\n",
    "        messages.append(message)\n",
    "\n",
    "print(data)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "r = rsa(data, messages, spatial.distance.hamming, compute_jaccard_distance_score)\n",
    "print(r)\n",
    "\n",
    "r = rsa(data, messages, spatial.distance.hamming, levenshtein_ratio_and_distance)\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example language #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = 10\n",
    "colors = 10\n",
    "\n",
    "# create example dataset\n",
    "data = generate_dataset([shapes, colors])\n",
    "\n",
    "# create example language\n",
    "messages = []\n",
    "for i in range(shapes):\n",
    "    for j in range(colors):\n",
    "        \n",
    "        # create string\n",
    "        message = (i+1) * 'x ' + (j+1) * 'y '\n",
    "       \n",
    "        # seperate string\n",
    "        messages.append(message.split())\n",
    "    \n",
    "# print(data)\n",
    "# print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../metrics/rsa.py:54: UserWarning: Standard deviation of a space is 0 given distance function\n",
      "  rho = scipy.stats.pearsonr(sim_x, sim_y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.37391293238082607\n"
     ]
    }
   ],
   "source": [
    "r = rsa(data, messages, spatial.distance.hamming, compute_jaccard_distance_score)\n",
    "print(r)\n",
    "\n",
    "r = rsa(data, messages, spatial.distance.hamming, levenshtein_ratio_and_distance)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example language #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects in the dataset:  18\n"
     ]
    }
   ],
   "source": [
    "# need language that combines the shape vectors\n",
    "shapes = 3\n",
    "colors = 3\n",
    "size = 2\n",
    "\n",
    "attributes = [shapes, colors, size]\n",
    "\n",
    "# create example dataset\n",
    "data = generate_dataset([shapes, colors, size])\n",
    "print('Number of objects in the dataset: ', len(data))\n",
    "\n",
    "# create vocabulary\n",
    "vocab = []\n",
    "alpha = 'a'\n",
    "for i in range(0, 26): \n",
    "    vocab.append(alpha) \n",
    "    alpha = chr(ord(alpha) + 1)\n",
    "\n",
    "# split it into 3 parts\n",
    "poss_attr = set()\n",
    "\n",
    "for obj in data:\n",
    "    # extract attributes\n",
    "    attr = np.where(obj == 1)\n",
    "\n",
    "    # split these lists into lists of length 2 \n",
    "    split_attr = combinations(attr[0],2)\n",
    "    \n",
    "    for sa in split_attr:\n",
    "        poss_attr.add(sa)\n",
    "    \n",
    "    \n",
    "# convert to list\n",
    "poss_attr = list(poss_attr)\n",
    "\n",
    "# create messages\n",
    "messages = []\n",
    "\n",
    "# loop through the dataset, find all possible attributes\n",
    "for obj in data:\n",
    "    \n",
    "    # create message\n",
    "    message = []\n",
    "    \n",
    "    # extract attributes\n",
    "    attr = np.where(obj == 1)\n",
    "    \n",
    "    # split these lists into lists of length 2 \n",
    "    split_attr = combinations(attr[0],2)\n",
    "    \n",
    "    # find index of attribute\n",
    "    for sa in split_attr:\n",
    "        char_index = poss_attr.index(sa)\n",
    "        \n",
    "        # extract character\n",
    "        message.append(vocab[char_index])\n",
    "\n",
    "    # randomly remove and element\n",
    "    del message[random.randint(0,2)]\n",
    "    \n",
    "    messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4588314677411236\n",
      "0.4588314677411236\n"
     ]
    }
   ],
   "source": [
    "r = rsa(data, messages, spatial.distance.hamming, compute_jaccard_distance_score)\n",
    "print(r)\n",
    "\n",
    "r = rsa(data, messages, spatial.distance.hamming, levenshtein_ratio_and_distance)\n",
    "print(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
